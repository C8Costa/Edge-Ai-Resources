# üß† Frameworks & Libraries

A collection of tools and runtimes for deploying AI models on edge devices.
##### Cross‚ÄëPlatform ‚ÄúMobile/Embedded‚Äù Runtimes** 
General‚Äëpurpose, lightweight inference engines you can embed into mobile apps or edge devices regardless of vendor:
- **[TensorFlow Lite](https://www.tensorflow.org/lite)** - Lightweight version of TensorFlow for mobile and embedded devices.
- **[ExecuTorch](https://pytorch.org/mobile/home/)** - Mobile deployment and model serialization with TorchScript.
- **[ONNX Runtime](https://onnxruntime.ai/)** - Cross-platform, high-performance scoring engine for ML models.
- **[Apache TVM](https://tvm.apache.org/)** - A open-source machine learning compiler framework for CPUs, GPUs, and machine learning accelerators.
- **[Edge Impulse - Edge Ai Platform](https://edgeimpulse.com/product?_gl=1*1sp61fb*_up*MQ..*_ga*MTUzMzA1Njk2My4xNzUzNzIyMDAx*_ga_1QH4BGX503*czE3NTM3MjIwMDEkbzEkZzEkdDE3NTM3MjIxNjIkajI4JGwwJGgxNjU1NjkzOTgz)** - Let's users collect sensor data, build and version ML pipelines, shrink models with its **EON‚ÄØCompiler**, and generate turnkey firmware for deployment on a variety of edge devices.

---
##### Accelerator‚ÄëSpecific Inference Toolkits
Optimized stacks from silicone manufacturers (GPU, FPGA, CPU)  :

- **[TensorRT](https://developer.nvidia.com/tensorrt)** NVIDIA‚Äôs GPU‚Äëfocused, mixed‚Äëprecision inference library.
- **[AMD Vitis AI](https://xilinx.github.io/Vitis-AI/3.5/html/index.html)** - Deep‚Äëlearning dev stack targeting AMD‚ÄëXilinx FPGAs and adaptive SoCs.
- **[OpenVINO](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html)** - Intel‚Äôs toolkit for optimizing + deploying inference on CPUs, iGPUs, VPUs and FPGAs.
- **[STM32Cube.AI](https://www.st.com/en/embedded-software/x-cube-ai.html)** - ST‚Äôs code generator to run neural nets on STM32 microcontrollers.
- **[e-AI Development Environment](https://www.renesas.com/us/en/e-ai-development-environment-microcontrollers#overview)** - Tools for Running Learned AI on Renesas MCUs and MPUs.

-**[nncase](https://github.com/kendryte/nncase)** - Open deep learning compiler stack for Kendryte AI accelerators